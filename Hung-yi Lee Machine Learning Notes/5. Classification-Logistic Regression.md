## 5. Classification: Logistic Regression

### Step 1: Function Set

逻辑回归是非线性，输出0或1.

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.1.PNG)

### Step 2: Goodness of a Function

计算出Loss函数

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.2.PNG)

### Step 3: Find the best function

对权重w求偏导

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.3.PNG)

### 逻辑回归 VS 线性回归

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.4.PNG)

### Generative v.s. Discriminative

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.5.PNG)

### Softmax，Cross Entropy

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.6.PNG)

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.7.PNG)

### Deep Learning！

![](https://github.com/steveLauwh/DeepLearning-notes/raw/master/Hung-yi%20Lee%20Machine%20Learning%20Notes/image/5.8.PNG)
